

| **é¢œè‰²** | **ä»£è¡¨å«ä¹‰**       | **é€‚ç”¨åœºæ™¯**                                 |
| ------ | -------------- | ---------------------------------------- |
| **çº¢è‰²** | **æ ¸å¿ƒè´¡çŒ®/æ ¸å¿ƒç»“è®º**  | è®ºæ–‡è§£å†³çš„ç—›ç‚¹ã€Abstractå’ŒConclusionçš„å…³é”®å¥ã€‚         |
| **é»„è‰²** | **é‡è¦å®šä¹‰/æ¦‚å¿µ**    | ç¬¬ä¸€æ¬¡å‡ºç°çš„ä¸“ä¸šæœ¯è¯­ï¼ˆå¦‚ï¼šInductive Bias, Zero-shotï¼‰ã€‚ |
| **è“è‰²** | **æ•°å­¦å…¬å¼/ç†è®ºä¾æ®**  | æŸå¤±å‡½æ•° Loss Functionã€æ³¨æ„åŠ›æœºåˆ¶å…¬å¼ã€‚              |
| **ç»¿è‰²** | **å®éªŒç»“æœ/æ€§èƒ½æ•°æ®**  | SOTA è¡¨ç°ã€æ¶ˆèå®éªŒçš„å…³é”®æ•°æ®ã€‚                       |
| **ç´«è‰²** | **å€¼å¾—å€Ÿé‰´çš„ä»£ç /æ–¹æ³•** | å®ç°ç»†èŠ‚ï¼Œå¦‚â€œä½¿ç”¨äº† AdamW ä¼˜åŒ–å™¨â€ã€â€œå­¦ä¹ ç‡è¡°å‡ç­–ç•¥â€ã€‚         |
| **æ©™è‰²** | **ä¸è¶³/æœªæ¥å·¥ä½œ**    | ä½œè€…æ‰¿è®¤çš„é™åˆ¶ï¼ˆLimitationsï¼‰ï¼Œè¿™å¾€å¾€æ˜¯ä½ çš„é€‰é¢˜åˆ‡å…¥ç‚¹ã€‚        |
| **ç°è‰²** | **èƒŒæ™¯/å¼•ç”¨æ–‡çŒ®**    | ç»å…¸çš„å‚è€ƒæ–‡çŒ®ï¼Œæ ‡è®°ä»¥åè¦å»è¯»ã€‚                         |
| **é’è‰²** | **ä¸ªäººç–‘é—®/éšç¬”**    | è‡ªå·±è¯»ä¸æ‡‚çš„åœ°æ–¹ï¼Œå¾…æŸ¥é˜…èµ„æ–™æˆ–é—®å¯¼å¸ˆã€‚                      |
# ğŸ“„ [Paper Study] {{title}} {{date}}

## 1. å¿«é€Ÿé¢„è§ˆ (Quick Read - 10min)
- **å¹´ä»½/ä¼šåˆŠï¼š** {{YEAR}} / #CVPR #ICCV #ECCV #Arxiv
- **é¢†åŸŸæ ‡ç­¾ï¼š** #CV/{{åˆ†ç±»/æ£€æµ‹/åˆ†å‰²/åº•å±‚}} 
- **æ ¸å¿ƒç—›ç‚¹ (Motivation)ï¼š**
    - 
- **æ ¸å¿ƒè´¡çŒ® (Key Idea)ï¼š**
    - 
- **ä»£ç ä»“åº“ï¼š** [GitHub Link]
- **æ˜¯å¦å€¼å¾—ç²¾è¯»ï¼š** ğŸŸ¢ å¿…è¯» / ğŸŸ¡ ç•¥è¯» / ğŸ”´ ä»…ä½œå‚è€ƒ

---

## 2. å†…å®¹æ•´ç†/æ ¸å¿ƒæ¶æ„ä¸æ•°æ®æµ (Architecture & Data Flow)

- **å†…å®¹æ•´ç†**
	- æ ¸å¿ƒåŠŸèƒ½
		- Users can segment all instances of a visual concept specified by a short noun phrase, image exemplars (positive or negative), or a combination of both.
		- Promptçš„ç±»å‹ï¼šphrasesï¼Œimage exemplars
	- Modelç»“æ„
		- The model consists of a detector and a tracker that **share a vision encoder.**
			- Detector is a **DETR-based** model conditioned on **text, geometry, and image exemplars.** ä¸DETRä¸åŒï¼Œè¿™ä¸ªdetectorè¿›è¡Œå¼€é›†åŒ¹é…ï¼Œæœ¬è´¨ä¸Šæ˜¯ **"Text-Conditioned Class-Agnostic Proposal Generator" (åŸºäºæ–‡æœ¬æ¡ä»¶çš„ç±»åˆ«æ— å…³å€™é€‰ç”Ÿæˆå™¨)**
			- è¿™ä¸ªdetectoré¢„æµ‹ **æ˜¯å¦åŒ¹é…å½“å‰Prompt**ï¼Œè¾“å…¥åŒ…æ‹¬å›¾åƒ *I* å’ŒPrompt Embedding *T* (æ¥è‡ªConcept Encoder)$$Output=Sigmoid(Score(q,T))$$queryçš„è¯­ä¹‰å®Œå…¨ç”±PromptåŠ¨æ€å®šä¹‰, Queryä»…å½“è§†è§‰ç‰¹å¾ä¸text promptå…±æŒ¯æ—¶å¾—åˆ°é«˜å¾—åˆ†
			- $$P_{final}=P_{presence}(I,T)*P_{los}(q_i|I,T)$$
		- **Detector** :  
			- â€œThe fusion encoder then accepts the unconditioned embeddings from the image encoder and conditions them by cross-attending to the prompt tokens. The fusion is followed by a DETR-like decoder, where learned object queries cross-attend to the conditioned image embeddings from the fusion encoder.â€ (Carion ç­‰, 2025, p. 3) 
				**Multimodal Decoder**å¢å¼ºåŸå§‹å›¾ç‰‡ç‰¹å¾ï¼›**Detector Decoder**é¢„æµ‹Nä¸ªbounding boxä»¥åŠå®ƒä»¬å±äºpromptçš„æ¦‚ç‡, è§Fig. 10
			- **Multimodal Decoder (Fusion Encoder)** å¢å¼ºåŸå§‹å›¾ç‰‡ç‰¹å¾
				- Appendix: A stack of 6 transforrmers blocks with **self- and cross-attention (to prompt tokens)** layers followed by an MLP. å®ƒè¾“å‡º **conditioned frame-embedding**
			- **Detector Decoder**  A stack of 6 transformer blocks. $Q$ learned *object queries* **self-attend** to each other and **cross attend to the prompts tokens**, followed by an MLP
				- å…¶ä¸­ä½¿ç”¨äº†è¯¸å¦‚look-forward twiceçš„å¢å¼ºæ–¹æ³• [[DINO Detection]]
			- **Semantic Head:** â€œwe also have a semantic segmentation head, which predicts a binary label for every pixel in the image, indicating whether or not it corresponds to the prompt.â€ (Carion ç­‰, 2025, p. 4)
				å¯¹Conditioned Image Featuresè¿›è¡Œä¸Šé‡‡æ ·ï¼Œé€šè¿‡ä¸€ä¸ªç®€å•çš„å·ç§¯å±‚ç›´æ¥è§‚æµ‹HÃ—Wçš„æ¦‚ç‡å›¾ã€‚ä¸åŒºåˆ†å…·ä½“çš„ä¸ªä½“ï¼Œåªå›ç­”â€œå“ªäº›åƒç´ å±äºè¿™ä¸ªConceptâ€
				- **semantic and the **instance mask** share the same segmentation head
			- **Presence Tokenï¼š** Decouple the recognition and localization process, å› ä¸ºrecognitionéœ€è¦contextual cues from the entire imageï¼Œå¯¹äºqueriesæ˜¯"counterproductive"çš„ï¼Œå› æ­¤å¼•å…¥presence token
				- $$p(query_i\text{ matches NP})=p(query_i\text{ matches NP|  NP appears in image}\cdot p(\text{NP appears in image})$$
					- $p(\text{NP appears in image)}$: *presence token*, which is added to our decoder and then fed through an MLP classification head.
					- presence score shared by all queries $S_{final_query_i}=S_{presence}\times S_{local_query_i}$
					- $$\mathcal{L}_{total} = \mathcal{L}_{presence}(S_{presence}, y_{exist}) + \mathbf{1}_{\{y_{exist}=1\}} \cdot \mathcal{L}_{local}(\text{Queries}, \text{GT\_Boxes})$$
						- only compute local loss when the GT  exists
					
		- **Tracker**: 
			- Trackerç»“åˆå½“å‰å¸§å’Œmemory bankä¸­çš„ä»¥å‰å¸§é¢„æµ‹åŒæ—¶å­˜åœ¨äºå½“å‰å¸§å’Œä»¥å‰å¸§ä¸­çš„objectå¹¶ç”Ÿæˆæ©ç 
			- inheritted from SAM 2 **memory attention** and **decoder** module to propagate the masks
			- **subtle improvements have been indicated** see appendix C.3 Video Implementation Details
			
		- **Masklet Matcher:** å¼•å…¥åŒ¹é…å‡½æ•° Merge existing and newly detected masks: simple IoU based matching functionâ€ (Carion ç­‰, 2025, p. 5)
- **æ¨¡å‹ç»“æ„å›¾ï¼š**
  ![[Pasted image 20260206232103.png]]
- ![[Pasted image 20260206232115.png]]
- **å¼ é‡å˜åŒ– (Tensor Shapes)ï¼š**
    -

---

## 3. æ·±åº¦æŠ€æœ¯æ£€æŸ¥æ¸…å• (Direction-Specific Checklist)

### ğŸŸ£ å›¾åƒåˆ†å‰² (Segmentation)
- [ ] **è§£è€¦æ–¹å¼:** å®ƒæ˜¯å¦‚ä½•ä»ä½åˆ†è¾¨ç‡æ¢å¤åˆ°é«˜åˆ†è¾¨ç‡çš„ï¼Ÿ(ä¸Šé‡‡æ ·/åå·ç§¯/Skip Connection?)
- [ ] **åˆ†ç±»ç²’åº¦:** å®ƒæ˜¯å¦‚ä½•å®ç°åƒç´ çº§ (Pixel-wise) ç²¾å‡†åˆ†ç±»çš„ï¼Ÿ
- [ ] **è¾¹ç•Œå¤„ç†:** å¯¹ç‰©ä½“çš„è¾¹ç¼˜å’Œç»†èŠ‚å¤„æ˜¯å¦æœ‰ç‰¹æ®Šçš„ä¼˜åŒ–å¤„ç†ï¼Ÿ


---

## 4. æ•°å­¦è¡¨è¾¾ä¸ä»£ç å¤ç° (Math & Code)
- **æ ¸å¿ƒå…¬å¼ï¼š**

- **ä»£ç æ ¸å¿ƒé€»è¾‘ (GitHub Snippets)ï¼š**
```python
# è®°å½•å¤ç°æ—¶å‘ç°çš„è®ºæ–‡æ ¸å¿ƒå‡½æ•°å®ç°é€»è¾‘
def forward(self, x):
    # ä¾‹å¦‚ï¼šè¿™é‡Œæ˜¯è®ºæ–‡æåˆ°çš„ Residual Connection
    identity = x
    out = self.conv_layers(x)
    return out + identity
````

---

## 5. æœ¬ç§‘ç”Ÿä¸“é¡¹ï¼šåŸºç¡€è¡¥è¯¾ä¸ç–‘é—® (To-Learn)

- [ ] **åŸºç¡€æ¦‚å¿µè¡¥è¯¾ (ç”¨ Obsidian åŒé“¾é“¾æ¥)ï¼š**
    - 
- [ ] **é‡åˆ°çš„å‘ï¼š** 
    
- [ ] å‡†å¤‡é—®å¸ˆå…„çš„é—®é¢˜ï¼š
    
---

## 6. å…³è”é˜…è¯»ä¸æ€»ç»“ (Summary & Links)

- **ä¸Šä¸€ä»£å·¥ä½œï¼š** 
    
- **æ ¸å¿ƒå¯¹æ¯”ï¼š** 
    


